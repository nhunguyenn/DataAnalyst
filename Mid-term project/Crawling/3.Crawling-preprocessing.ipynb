{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5510a572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 713)\t1.0\n",
      "  (1, 217)\t1.0\n",
      "  (2, 278)\t1.0\n",
      "  (3, 502)\t1.0\n",
      "  (4, 54)\t1.0\n",
      "  (5, 719)\t1.0\n",
      "  (6, 529)\t1.0\n",
      "  (7, 593)\t1.0\n",
      "  (8, 382)\t1.0\n",
      "  (9, 9)\t1.0\n",
      "  (10, 243)\t1.0\n",
      "  (11, 700)\t1.0\n",
      "  (12, 134)\t1.0\n",
      "  (13, 415)\t1.0\n",
      "  (14, 424)\t1.0\n",
      "  (15, 712)\t1.0\n",
      "  (16, 459)\t1.0\n",
      "  (17, 318)\t1.0\n",
      "  (18, 391)\t1.0\n",
      "  (19, 112)\t1.0\n",
      "  (20, 742)\t0.6928432584376695\n",
      "  (20, 136)\t0.7210882187620823\n",
      "  (21, 659)\t1.0\n",
      "  (22, 573)\t0.7166016276495422\n",
      "  (22, 531)\t0.6974826931544803\n",
      "  :\t:\n",
      "  (1679, 547)\t1.0\n",
      "  (1680, 588)\t1.0\n",
      "  (1681, 301)\t1.0\n",
      "  (1682, 423)\t1.0\n",
      "  (1683, 7)\t1.0\n",
      "  (1684, 301)\t1.0\n",
      "  (1685, 200)\t1.0\n",
      "  (1686, 226)\t1.0\n",
      "  (1687, 19)\t1.0\n",
      "  (1688, 497)\t1.0\n",
      "  (1690, 759)\t1.0\n",
      "  (1691, 627)\t1.0\n",
      "  (1692, 178)\t1.0\n",
      "  (1693, 360)\t1.0\n",
      "  (1695, 234)\t1.0\n",
      "  (1696, 513)\t1.0\n",
      "  (1697, 341)\t1.0\n",
      "  (1698, 668)\t1.0\n",
      "  (1700, 593)\t1.0\n",
      "  (1701, 756)\t0.6424812688032868\n",
      "  (1701, 249)\t0.7663013892959603\n",
      "  (1702, 360)\t1.0\n",
      "  (1703, 676)\t1.0\n",
      "  (1704, 71)\t1.0\n",
      "  (1705, 41)\t1.0\n"
     ]
    }
   ],
   "source": [
    "api_key = \"AIzaSyBbuCLbRgxHQiUCc1rKPUUNmJxJwedtWIA\" # Nhập API key \n",
    "\n",
    "from apiclient.discovery import build\n",
    "youtube = build('youtube', 'v3', developerKey=api_key)\n",
    "\n",
    "import pandas as pd\n",
    "import unicodecsv as csv\n",
    "import string\n",
    "import re\n",
    "import io\n",
    "from string import digits\n",
    "import nltk\n",
    "from underthesea import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import nltk\n",
    "\n",
    "ID = \"6Q7mfthgMAU\" # Nhập ID của video \n",
    "\n",
    "box = []  #tạo một list rỗng để chứa dữ liệu crawl về từ video\n",
    "\n",
    "\n",
    "# câu 3.1\n",
    "def scrape_comments():\n",
    "    data = youtube.commentThreads().list(part='snippet', videoId=ID, maxResults='100', textFormat=\"plainText\").execute()\n",
    "\n",
    "    for i in data[\"items\"]:\n",
    "        name = i[\"snippet\"]['topLevelComment'][\"snippet\"][\"authorDisplayName\"]\n",
    "        comment = i[\"snippet\"]['topLevelComment'][\"snippet\"][\"textDisplay\"]\n",
    "        published_at = i[\"snippet\"]['topLevelComment'][\"snippet\"]['publishedAt']\n",
    "        likes = i[\"snippet\"]['topLevelComment'][\"snippet\"]['likeCount']\n",
    "        replies = i[\"snippet\"]['totalReplyCount']\n",
    "\n",
    "        box.append([name, comment, published_at, likes, replies])\n",
    "\n",
    "    \n",
    "\n",
    "    df = pd.DataFrame({'Comment': [i[1] for i in box] })\n",
    "    df[0:200].to_csv('crawl_data_Youtube.csv',index=False, header=False)\n",
    "    \n",
    "    return df[0:200]\n",
    "\n",
    "def convert_to_string(list):\n",
    "    mystring = \"\".join(list)\n",
    "    return mystring\n",
    "\n",
    "\n",
    "# câu 3.2: Text preprocessing\n",
    "# chuyển đổi để xóa các icon trong câu\n",
    "def remove_emoji(string):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                               u\"\\U0001F600-\\U0001F64F\"  # biểu tượng cảm xức\n",
    "                               u\"\\U0001F300-\\U0001F5FF\"  # ký hiệu & tranh\n",
    "                               u\"\\U0001F680-\\U0001F6FF\"  # ký hiệu\n",
    "                               u\"\\U0001F1E0-\\U0001F1FF\"  # cờ\n",
    "                               u\"\\U00002500-\\U00002BEF\" \n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U000024C2-\\U0001F251\"\n",
    "                               u\"\\U0001f926-\\U0001f937\"\n",
    "                               u\"\\U00010000-\\U0010ffff\"\n",
    "                               u\"\\u2640-\\u2642\"\n",
    "                               u\"\\u2600-\\u2B55\"\n",
    "                               u\"\\u200d\"\n",
    "                               u\"\\u23cf\"\n",
    "                               u\"\\u23e9\"\n",
    "                               u\"\\u231a\"\n",
    "                               u\"\\ufe0f\"  # dingbats\n",
    "                               u\"\\u3030\"\n",
    "                               \"]+\", flags=re.UNICODE)\n",
    "    \n",
    "    string1 = emoji_pattern.sub(r'', string)\n",
    "    \n",
    "    special_char = '@_!#$%^&*()<>?/\\|}{~:;[].,'\n",
    "    \n",
    "    new_string = ''.join((filter(lambda i: i not in special_char, string1)))\n",
    "    \n",
    "    \n",
    "    return new_string\n",
    "   \n",
    "# xóa các ký tự đặc biệt    \n",
    "def remove_special_characters():\n",
    "\n",
    "    special_char = '@_!#$%^&*()<>?/\\|}{~:;[]'\n",
    "    \n",
    "    new_string = ''.join((filter(lambda i: i not in special_char, string)))\n",
    "    \n",
    "    return new_string\n",
    "\n",
    "#xóa số trong chữ có số\n",
    "def remove_number(string):\n",
    "    result = ''.join([i for i in string if not i.isdigit()])\n",
    "    return result\n",
    "\n",
    "# chuyển chữ cái viết hoa sang viết thường\n",
    "def text_lowercase(text):\n",
    "    return text.lower()\n",
    "\n",
    "    \n",
    "# hàm dùng để phân tách các từ ngữ \n",
    "def text_preprocessing(x):\n",
    "    \n",
    "    products_list = x.values.tolist() # chuyển dataframe thành list\n",
    "    listofstring = []  # khởi tạo list rỗng \n",
    "    \n",
    "    # cho vòng lặp i đi qua từng Comments trong products_list\n",
    "    for i in products_list: \n",
    "        str = ''.join(i) # chuyển từng thành phần trong list sang str để xử lý \n",
    "        mystring = remove_emoji(str)  # loại bỏ icon\n",
    "        mystring = remove_number(mystring)  # loại bỏ số\n",
    "        mystring = text_lowercase(mystring)  # chuyển viết hoa về viết thường\n",
    "        listofstring.append(word_tokenize(mystring))  # sử dụng thư viện của underthesea để tách từ Tiếng Việt có nghĩa\n",
    "    \n",
    "    return listofstring\n",
    "\n",
    "# câu 3.2: tính TF_IDF\n",
    "def TF_IDF(x):\n",
    "    \n",
    "    #list1 chứa các từ ngữ là đã đc phân tách theo từng câu\n",
    "    list1 = text_preprocessing(x) \n",
    "    \n",
    "    list_pre = []\n",
    "    \n",
    "    # cho từng phần tử của list1 vào list_pre\n",
    "    for i in list1:\n",
    "        for j in i:\n",
    "            list_pre.append(j)\n",
    "            \n",
    "    vectorizer = TfidfVectorizer()\n",
    "    vectorizer.fit(list_pre)\n",
    "    list_pre = vectorizer.transform(list_pre)\n",
    "    \n",
    "    return list_pre\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    x = scrape_comments()  #gọi hàm\n",
    "       \n",
    "#     print(x) # print hàm scrape_comments()\n",
    "    \n",
    "#     print(text_preprocessing(x)) # print hàm text_preprocessing(x)\n",
    "\n",
    "#     print(TF_IDF(x))\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2919963",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
